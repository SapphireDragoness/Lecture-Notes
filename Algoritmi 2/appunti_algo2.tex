\documentclass[11pt]{article}
\usepackage[margin=.8in]{geometry}
\usepackage[italian]{babel}
\usepackage{tikz}
\usepackage{amsfonts} 
\usepackage{amsthm}
\usepackage{thmtools}
\usepackage[Algoritmo]{algorithm}
\usepackage{algpseudocode}
\usepackage{float}
\usepackage{hyperref}


\title{Appunti Algoritmi 2}

\newtheorem*{theorem}{Teorema}
\newtheorem*{proprietà}{Proprietà}
\newtheorem*{lemma}{Lemma}
\theoremstyle{proprietà}
\renewcommand{\listalgorithmname}{Algoritmi}

\hypersetup{
    colorlinks=true,
    linkcolor=black,
    filecolor=magenta,      
    urlcolor=cyan,
    }

\urlstyle{same}

\begin{document}
\pagenumbering{roman}
\tableofcontents
\listofalgorithms
\newpage
\pagenumbering{arabic}
\section{Grafi come strutture dati}
\subsection{Introduzione e terminologia}
Un grafo è una coppia di elementi (insiemi) \textbf{G=(V,E)} e consiste in:
\begin{itemize}
    \item un insieme $V$ di \textbf{vertici} (o \textbf{nodi})
    \item un insieme $E$ ($E$ sottoinsieme del prodotto cartesiano $V\times V$) di coppie di vertici, detti \textbf{archi}
    o \textbf{spigoli}; ogni arco connette due vertici
\end{itemize}
I grafi possono essere:
\begin{itemize}
    \item \textbf{orientati}: relazioni asimmetriche, insieme di coppie ordinate
    \item \textbf{non orientati}: relazioni simmetriche, insieme di coppie non ordinate
\end{itemize}
Un arco è \textbf{incidente} per i nodi che si toccano.\\
Il \textbf{grado} di un vertice è dato dal numero di archi incidenti.\\
Un vertice $B$ è \textbf{adiacente} ad $A$ se da $B$ si può percorrere un solo arco e giungere ad $A$.\\
Un \textbf{sottografo} è una porzione di grafo (notazione $H\subseteq G$): i vertici di $H$ sono sottoinsieme dei vertici di $G$ 
e gli archi di $H$ sono sottoinsieme degli archi di $G$.\\
Un \textbf{cammino} è una sequenza ordinata di archi che collegano due nodi. I cammini devono rispettare l'orientamento 
degli archi. La \textbf{lunghezza} è il numero di archi di cui è composto un cammino.\\ Un cammino si dice \textbf{semplice} 
se non passa due volte per lo stesso vertice. Se esiste almeno un cammino $p$ tra i vertici $v$ e $w$, si dice che $w$ è 
\textbf{raggiungibile} da $v$. Inoltre $v$ è un \textbf{antenato} di $w$ e $w$ è un \textbf{discendente} di $v$.\\ 
Un cammino tra due nodi $v$ e $w$ si dice \textbf{minimo} se tra $v$ e $w$ non esiste nessun altro cammino di lunghezza 
minore. La lunghezza del cammino minimo è detta \textbf{distanza} ($\delta (v,w)$).\\
Un grafo può essere \textbf{pesato}. La funzione peso è definita come $W:E\rightarrow \mathbb{R}$; per ogni arco
$(v,w)\in E,W(v,w)$ definisce il \textbf{peso} di $(v,w)$. In un grafo pesato, la lunghezza/peso di un cammino si calcola 
sommando i pesi degli archi che contiene.\\
I grafi non orientati possono essere:
\begin{itemize}
    \item \textbf{connessi}: esiste un cammino da ogni vertice verso ogni altro vertice
    \item \textbf{non connessi}
\end{itemize}
I grafi orientati possono essere:
\begin{itemize}
    \item \textbf{fortemente connessi}: esiste un cammino da ogni vertice verso ogni altro vertice
    \item \textbf{debolmente connessi}: ignorando il verso degli archi
\end{itemize}
Un cammino $\langle w_1,w_2,...,w_n \rangle$ si dice \textbf{chiuso} se $w_1=w_n$. Un cammino chiuso, semplice, di lunghezza 
almeno 1 si dice \textbf{ciclo}. Se un grafo non contiene cicli, si dice \textbf{aciclico}.\\
Un \textbf{grafo completo} è un grafo con un arco per ogni coppia di vertici. Un grafo completo ha numero di archi $E$ pari 
a $|E| = \frac{|V|(|V|-1)}{2}$.\\
Un grafo non orientato, connesso e aciclico è definito \textbf{albero libero}. Se un vertice è designato ad essere radice, 
si definisce \textbf{albero radicato}. Un grafo non orientato, aciclico ma non connesso è definito \textbf{foresta}.
\subsection{Rappresentazione}
Per valutare un approccio di rapppresentazione, bisogna considerare lo \textbf{spazio} occupato dalla struttura dati e il 
\textbf{costo computazionale} delle operazioni da effettuare su di essa.
\subsubsection{Lista di archi}
Dati $n$ (numero di vertici) e $m$ (numero di archi), lo spazio occupato è $\mathcal{O}(n+m)$: è una rappresentazione 
inefficiente, in quanto bisogna percorrere tutto il grafo per scandire la lista di archi. Introdurre un vertice o arco ha 
costo $\mathcal{O}(1)$, ma la rimozione ha costo $\mathcal{O}(m)$.
\subsubsection{Liste di adiacenza}
Ogni vertice $v$ ha una lista contenente i vertici ad esso adiacenti. Calcolare il grado di un vertice è un'operazione 
semplice, in quanto basta scorrere la lista di adiacenza. Occupa spazio $\mathcal{O}(n+m)$, ed è adatta per grafi \textbf{sparsi} 
(il numero di archi è molto minore del numero di vertici).
\subsubsection{Liste di incidenza}
Ogni vertice $v$ ha una lista contenente un riferimento agli archi ad esso incidenti. Occupa spazio $\mathcal{O}(n+m)$.
\subsubsection{Matrici di adiacenza}
Il grafo è rappresentato tramite una matrice di interi di grandezza $n \times n$ (spazio occupato $\mathcal{O}(n^2)$); è 
adatta per grafi \textbf{densi}. Calcolare il grado e archi incidenti ha costo $\mathcal{O}(n)$ (basta scorrere la matrice). 
La modifica dei vertici ha costo $\mathcal{O}(n^2)$ in quanto bisogna ricostruire completamente la matrice.
Una matrice di adiacenza rappresenta anche la presenza di un cammino di lunghezza 1 tra ogni coppia di vertici $v$ e $w$. 
In particolare, $v \rightarrow_1 w$ se e solo se $M[v,w]\neq 0$: moltiplicando la matrice per sè stessa, il risultato è 
diverso da 0 solo se esiste un cammino di lunghezza 2 (e via dicendo).
\subsubsection{Matrici di incidenza}
Il grafo è rappresentato tramite una matrice di interi di grandezza $n \times m$ (spazio occupato $\mathcal{O}(n \times m)$), 
in cui le righe indicizzano i vertici e le colonne indicizzano gli archi.
\section{Visite}
\subsection{Visita generica}
Una \textbf{visita} di un grafo $G$ permette di esaminare i nodi e gli archi in maniera sistematica, senza passare due 
volte per lo stesso nodo.
\subsubsection{Inizializzazione}
Una tattica per evitare di visitare un nodo più volte è quella di mappare lo stato della visita ad un colore:
\begin{itemize}
    \item \textbf{bianco} (o \textbf{nodi inesplorati}): vertice non ancora esplorato
    \item \textbf{grigio} (o \textbf{nodi aperti}): vertice visitato, ma con nodi adiacenti ancora inesplorati
    \item \textbf{nero} (o \textbf{nodi chiusi}): vertice visitato, con adiacenti esplorati
\end{itemize}
Dati $n$ nodi, si utilizza un vettore \textit{color} di colori, di grandezza $n$: all'inizio della visita, tutte le celle 
del vettore \textit{color} sono impostate a \textit{white}.
\begin{algorithm}[H]
    \caption{INIZIALIZZA(G)}
    \begin{algorithmic}
        \State color $\gets$ vettore di lunghezza n
        \For{ogni $u\in V$}
        \algstore{1}
    \end{algorithmic}
\end{algorithm}
\begin{algorithm}[h]
    \begin{algorithmic}
        \algrestore{1}
            \State color[$u$] $\gets$ white
        \EndFor
    \end{algorithmic}
\end{algorithm}
La visita parte da un nodo $s$, detto \textbf{nodo sorgente}.
\begin{algorithm}[H]
    \caption{VISITA(G,s)}
    \begin{algorithmic}
        \State INIZIALIZZA(G)
        \State color $\gets$ gray
        \State \{visita $s$\}
        \While{ci sono vertici grigi}
            \State $u \gets$ scegli un vertice grigio
            \If{esiste $v$ bianco adiacente ad $u$}
                \State color[$v$] $\gets$ gray
                \State \{visita $v$\}
            \Else{ color[$v$] $\gets$ black}
            \EndIf
        \EndWhile
    \end{algorithmic}
\end{algorithm}
Il cambiamento di colore è \textbf{monotono} (bianco $\rightarrow$ grigio $\rightarrow$ nero).
\subsubsection{Invarianti}
Un'\textbf{invariante} è una condizione che è verificabile come vera sia all'inizio sia alla fine di un ciclo:
\begin{itemize}
    \item Invariante 1: se esiste un arco $(u,v)\in E$ ed $u$ è nero, allora $v$ è grigio o nero 
    \item Invariante 2: tutti i vertici grigi o neri sono raggiungibili dalla sorgente 
    \item Invariante 3: qualunque cammino dalla sorgente ad un vertice bianco deve contenere almeno un vertice grigio 
\end{itemize}
\begin{theorem}
    Al termine dell'algoritmo di visita, $v$ è nero se e solo se $v$ è raggiungibile dalla sorgente.
\end{theorem}
\begin{proof}
    Per l'invariante 2, all'uscita dal ciclo tutti i vertici neri sono raggiungibili da $s$. Dall'invariante 
    3 si ricava che tra $s$ e $v$ esiste almeno un vertice grigio, oppure $v$ non è bianco. Dato che la condizione di uscita 
    dal ciclo è quella che non esistano più vertici grigi, si ricava che $v$ non è bianco (cambiamento monotono) e non può 
    essere grigio. Quindi, all'uscita dal ciclo, tutti i vertici raggiungibili dalla sorgente sono neri.
\end{proof}
\subsubsection{Predecessori}
L'algoritmo può essere modificato in modo da ricordare, per ogni vertice che viene scoperto, quale vertice grigio ha permesso 
di scoprirlo, ossia ricordare l'arco percorso. Ad ogni vertice $u$ si associa un attributo $\pi[u]$ che rappresenta il 
vertice che ha permesso di scoprirlo.
\begin{algorithm}[H]
    \caption{VISITA(G,s)}
    \begin{algorithmic}
        \State INIZIALIZZA(G)
        \State color $\gets$ gray
        \State \{visita $s$\}
        \While{ci sono vertici grigi}        
        \algstore{3}
    \end{algorithmic}
\end{algorithm}
\begin{algorithm}[H]
    \begin{algorithmic}
        \algrestore{3}
        \State $u \gets$ scegli un vertice grigio
            \If{esiste $v$ bianco adiacente ad $u$}
                \State color[$v$] $\gets$ gray
                \State $\pi[v] \gets u$
                \State \{visita $v$\}
            \Else{ color[$v$] $\gets$ black}
            \EndIf
        \EndWhile
    \end{algorithmic}
\end{algorithm}
\begin{proprietà}
    Al termine dell'esecuzione di VISITA(G,s), tutti e soli i vertici neri diversi da $s$ hanno predecessore diverso da 
    NULL.
\end{proprietà}
Il sottografo dei predecessori è un albero (\textbf{albero dei predecessori}) di radice $s$.\\
Se il grafo non è connesso:
\begin{algorithm}[H]
    \caption{VISITA TUTTI I VERTICI(G)}
    \begin{algorithmic}
        \State INIZIALIZZA(G)
        \For{ogni $u\in V$}
            \If{color[$u$] = white} 
            \State VISITA(G,u)
            \EndIf
        \EndFor
    \end{algorithmic}
\end{algorithm}
\subsubsection{Gestione dei vertici grigi}
Per gestire i nodi grigi si usa una struttura dati ordinata $D$ (\textbf{frangia}). Sulla frangia è possibile eseguire le 
seguenti operazioni:
\begin{itemize}
    \item \textbf{Create()}: restituisce una $D$ vuota
    \item \textbf{Add(D,x)}: aggiunge un elemento x a $D$
    \item \textbf{First(D)}: restituisce il primo elemento di $D$
    \item \textbf{RemoveFirst(D)}: elimina il primo elemento di $D$
    \item \textbf{NotEmpty(D)}: restituisce vero se D contiene almeno un elemento, falso altrimenti
\end{itemize}
$D$ è una \textbf{coda} se Add(D,x) aggiunge l'elemento in coda a $D$, uno \textbf{stack} se Add(D,x) aggiunge l'elemento 
in testa a $D$.
\begin{algorithm}[H]
    \caption{VISITA(G,s)}
    \begin{algorithmic}
        \State INIZIALIZZA(G)
        \State Create() 
        \State color[$s$] $\gets$ gray
        \State \{visita $s$\}
        \State Add(D,s)
        \While{NotEmpty(D)}
        \State $u \gets$ First(D)
        \If{esiste $v$ bianco adiacente ad $u$}
            \State color[$v$] $\gets$ gray
        \algstore{5}
    \end{algorithmic}
\end{algorithm}
\begin{algorithm}[h]
    \begin{algorithmic}
        \algrestore{5}
            \State $\pi[v] \gets u$
            \State \{visita $v$\}
            \State Add(D,v)
        \Else
            \State color[$v$] $\gets$ black
            \State RemoveFirst(D)
        \EndIf
    \EndWhile
    \end{algorithmic}
\end{algorithm}
\subsubsection{Complessità}
Il costo di visita è $\mathcal{O}(n+adj)$: $adj$ è il tempo impiegato a controllare se esiste un nodo $v$ bianco adiacente 
ad $u$, e dipende dalla rappresentazione; $n$ è il numero di vertici, che vengono inseriti e rimossi da $D$.\\
Il costo di $adj$ è:
\begin{itemize}
    \item con lista di archi: bisogna scandire l'intera lista ($\mathcal{O}(m)$) per $n$ volte ($\mathcal{O}(n)$), quindi 
    $\mathcal{O}(n)+\mathcal{O}(n*m)=\mathcal{O}(mn)$
    \item con matrice di adiacenza: bisogna scandire l'intera riga della matrice ($\mathcal{O}(n)$), quindi $\mathcal{O}(n)+\mathcal{O}(n*n)=\mathcal{O}(n^2)$
    \item con liste di adiacenza: si possono ottimizzare le prestazioni utilizzando dei puntatori che puntano all'inizio 
    delle liste di adiacenza. Se l'elemento è grigio, il puntatore è spostato all'elemento successivo; quando il puntatore 
    giunge alla fine della lista, il primo elemento è colorato di nero. Ogni lista è percorsa una volta sola, in tutte le 
    iterazioni del ciclo. Complessità: $\mathcal{O}(n+m)$.
\end{itemize}
\subsection{Visita in ampiezza}
\subsubsection{Inizializzazione}
La \textbf{visita in ampiezza} (\textbf{BFS}, Breadth First Search), esamina i vertici del grafo in un ordine ben preciso,
costruendo un albero di visita chiamato \textbf{albero BFS}. Nell'albero BFS, ogni vertice si trova il più vicino possibile 
alla radice. La visita è realizzata usando la frangia come coda: quando un nodo grigio ha tutti gli adiacenti grigi, esso 
è rimosso dalla cosa (il vertice in testa rimane nella coda finchè non diventa nero).
\begin{algorithm}[h]
    \caption{VISITA BFS(G,s)}
    \begin{algorithmic}
        \State INIZIALIZZA(G)
        \State queue() 
        \State color[$s$] $\gets$ gray
        \State \{visita $s$\}
        \State enqueue(D,s)
        \While{NotEmpty(D)}
        \State $u \gets$ head(D)
        \If{esiste $v$ bianco adiacente ad $u$}
            \State color[$v$] $\gets$ gray
            \State $\pi[v] \gets u$
            \State \{visita $v$\}
            \State enqueue(D,v)
            \algstore{6}
    \end{algorithmic}
\end{algorithm}
\begin{algorithm}[h]
    \begin{algorithmic}
        \algrestore{6}
        \Else
            \State color[$v$] $\gets$ black
            \State dequeue(D)
        \EndIf
    \EndWhile
    \end{algorithmic}
\end{algorithm}
\subsubsection{Albero di visita}
L'albero BFS viene costruito a livelli; l'albero rappresenta i cammini minimi. Anche se le liste di adiacenza vengono 
invertite, i nodi per livello non cambiano.
Si può inizializzare un \textbf{vettore di distanze} (stimate) $d$, inizializzato ad infinito: se un determinato vertice non
è stato trovato (distanza $\infty$ a fine BFS), allora non è raggiungibile da $s$.
\subsubsection{Proprietà}
\begin{proprietà}[1]
    In D ci sono tutti e soli i vertici grigi.
\end{proprietà}
\begin{proprietà}[2]
    Se $\langle v_1,v_2,\dots ,v_n \rangle$ è il contenuto di D, allora:
    \begin{itemize}
        \item[i] $d[v_i] \leq d[v_{i+1}]$: i vertici sono ordinati per livelli nella coda
        \item[ii] $d[v_n] \leq d[v_1]+1$: la coda contiene al massimo due livelli
    \end{itemize}
\end{proprietà}
\begin{proof}
    Nel caso base, in $D$ è presente solo la sorgente. La proprietà 2 è vera.\\
    Il passo ha due casi:
    \begin{itemize}
        \item dequeue(D): o $D$ rimane vuota (banalmente vera), o rimangono $\langle v_2,\dots ,v_n \rangle$, e 
        \begin{itemize}
            \item[i.] le disuguaglianze sono ancora vere e quindi
            \item[ii.] anche $d[v_n] \leq d[v_1]+1 \leq d[v_2]+1$
        \end{itemize}
        \item enqueue(D,v): $v$ è reso figlio di $v_1$ e accodato, quindi $d[v]=d[v_1]+1$ e
        \begin{itemize}
            \item[i.] $d[v_n] \leq d[v_1]+1=d[v]$
            \item[ii.] $d[v]=d[v_1]+1 \leq d[v_1]+1$
        \end{itemize}
    \end{itemize}
\end{proof}
\subsubsection{Dimostrazione $d[v]=\delta(s,v)$}
\begin{lemma}[Invariante 4]
    $d[v]=\delta(s,v)$ per tutti i vertici grigi o neri.
\end{lemma}
\textit{\textbf{Dimostrazione $d[v] \geq \delta(s,v)$.}} Dato che l'albero dei predecessori $\pi$ contiene solo archi appartenenti 
a $G$, il cammino da $s$ a $v$ è un cammino che appartiene anche a $G$, quindi la lunghezza del cammino da $s$ a $v$ 
nell'albero è maggiore o uguale alla distanza tra $s$ e $v$.

\textit{\textbf{Dimostrazione $d[v] \leq \delta(s,v)$.}} Definiamo l'insieme dei vertici a distanza $k$ dalla sorgente nel grafo 
come $V_k={v\in V|\delta(s,v)=k}$ ($v_0$ contiene solo la sorgente).\\ Nel caso base, $d[v_0]\leq \delta(s,v)$ (distanza di 
$s$ da sè stesso: $0\leq 0$). Sia $v\in V_k$: allora $\delta(s,v)=k$ (per definizione).\\ Con $k>0$ (passo), esisterà almeno 
un vertice $w$ tale che $\delta(s,w)=k-1$ e $(w,v)\in E$, ovvero un arco che va da $v$ a $w$. Definiamo l'insieme dei vertici 
appartenenti a $V_{k-1}$ con arco entrante in $v$ come $U_{k-1}={w\in V_{k-1}|(w,v)\in E}$. Tra questi, sia $u$ il primo 
vertice di $U_{k-1}$ ad essere scoperto ed inserito nella coda: per politica FIFO, $u$ sarà anche il primo ad essere estratto
dalla coda. Quando guarderò i vertici adiacenti a $u$, $v$ sarà ancora bianco (perchè più lontano), e $v$ verrà inserito 
nell'albero come figlio di $u$, con $d[v]=d[u]+1$. Inoltre, per ipotesi induttiva, $d[u]\leq k-1$.\\
Quindi, quando inseriremo $v$ nell'albero:
\begin{itemize}
    \item $d[v]=d[u]+1$
    \item ma $d[u]\leq k-1$, quindi $d[v]\leq (k-1)+1$
    \item $d[v]\leq k$
\end{itemize}
\subsubsection{Distanza nell'albero BFS}
\begin{theorem}
    Al termine dell'esecuzione della visita BFS, si ha $d[v]=\delta(s,v)$ per tutti i vertici $v\in V$.
\end{theorem}
\begin{proof}
    caso base: se $v$ non è raggiungibile da $s$, allora $d[v]$ rimane $\infty$.\\
    altrimenti, $v$ è nero (per invariante 2). Per ogni vertice $v$ raggiungibile da $s$, il cammino da $s$ a $v$ sull'albero 
    ottenuto dalla visita è un \textbf{cammino minimo}.
\end{proof}
\subsection{Visita in profondità}
\subsubsection{Inizializzazione}
La \textbf{visita in profondità} (\textbf{DFS}, Depth First Search), esamina i vertici del grafo partendo dall'ultimo 
vertice incontrato. Si ottiene dall'algoritmo di visita generico, implementando la frangia come \textbf{stack}.
\begin{algorithm}
    \caption{VISITA DFS (ottimizzata)}
    \begin{algorithmic}
        \State D $\gets$ emptyStack(D)
        \State color[$s$] $\gets$ gray
        \State \{visita $s$\}
        \State push(D)
        \While{esiste $v$ non considerato adiacente a top(D)}
            \If{color[$v$] = white}
                \State color[$v$] = gray 
                \State $\pi[v] \gets$ top(D) 
                \State \{visita $s$\}
                \State push(D,s)
            \EndIf 
            \State color[top(D)] $\gets$ black
            \State pop(D)
        \EndWhile
    \end{algorithmic}
\end{algorithm}
\subsubsection{Caratteristiche dell'albero DFS}
Un vertice viene chiuso (colorato di nero) solo quando tutti i suoi discendenti sono stati chiusi.\\
Gli intervalli di attivazione di una qualunque coppia di vertici sono o \textbf{disgiunti} o \textbf{uno contenuto interamente 
nell'altro}. Questo è l'ordine delle attivazioni delle chiamate di una procedura ricorsiva, ed è quindi possibile costruire 
un algoritmo DFS ricorsivo. Inoltre, è possibile introdurre un contatore per ricordare l'ordine delle attivazioni.
\begin{algorithm}[H]
    \caption{VISITA DFS RICORSIVA(G,u)}
    \begin{algorithmic}
        \State color[$u$] $\gets$ gray
        \State \{visita $s$\}
        \algstore{8}
    \end{algorithmic}
\end{algorithm}
\begin{algorithm}[H]
    \begin{algorithmic}
        \algrestore{8}
        \State d[$u$] $\gets$ time
        \State time++
        \For{ogni $v$ adiacente ad $u$}
            \If{color[$v$] = white}
                \State $\pi[v] \gets$ $u$
                \State VISITA DFS RICORSIVA(G,v)
            \EndIf 
            \State color[$u$] $\gets$ black
            \State f[$u$] $\gets$ time
            \State time++
        \EndFor
    \end{algorithmic}
\end{algorithm}
\subsubsection{Teorema delle parentesi e corollari}
\begin{theorem}[Parentesi]
    In ogni visita DFS di un grafo, per ogni coppia di vertici $u$, $v$, una ed una sola delle seguenti condizioni è soddisfatta: 
    \begin{itemize}
        \item $d[u]<d[v]<f[v]<f[u]$ ed $u$ è un \textbf{antenato} di $v$ in un albero della foresta DFS 
        \item $d[v]<d[u]<f[u]<f[v]$ ed $u$ è un \textbf{discendente} di $v$ in un albero della foresta DFS
        \item $d[u]<f[u]<d[v]<f[v]$ e tra $u$ e $v$ non esiste relazione (non sono adiacenti)
    \end{itemize}
\end{theorem}
\begin{theorem}[Annidamento degli intervalli]
    Una visita DFS di un grafo colloca un vertice $v$ come discendente proprio di un vertice $u$ in un albero della foresta 
    DFS se e solo se $d[u]<d[v]<f[v]<f[u]$.
\end{theorem}
\begin{theorem}[Cammino bianco]
    In una foresta DFS, un vertice $v$ è discendente del vertice $u$ se e solo se al tempo d[$u$] $v$ è raggiungibile da 
    $u$ con un cammino contenente solo vertici bianchi.
\end{theorem}
La complessità della visita DFS è $\mathcal(O)(m+n)$ (come la visita generica).
\section{Aciclicità}
È possibile verificare la presenza di un ciclo tramite una visita DFS.
\subsection{Grafi orientati}
Un arco $\langle u,v \rangle$ viene \textbf{percorso} quando si incontra $v$ nella lista degli adiacenti ad $u$. Durante 
la DFS di un grafo orientato, ogni arco è percorso una volta sola. Definiamo:
\begin{itemize}
    \item \textbf{Arco dell'albero}: arco inserito nella foresta DFS
    \item \textbf{Arco all'indietro}: arco che collega un vertice ad un suo antenato
    \item \textbf{Arco in avanti}: arco che collega un vertice ad un suo discendente 
    \item \textbf{Arco di attraversamento}: arco che collega due vertici che non sono in relazione 
\end{itemize}
Durante la visita di un grafo orientato, un arco $\langle u,v \rangle$ viene percorso quando si incontra $v$ nella lista 
degli adiacenti ad $u$. In quel momento, color[$v$] può essere:
\begin{itemize}
    \item \textbf{bianco}: $\langle u,v \rangle$ è un \textbf{arco dell'albero}
    \item \textbf{grigio}: $u$ è un discendente di $v$, $\langle u,v \rangle$ è un \textbf{arco all'indietro} 
    \item \textbf{nero}: $\langle u,v \rangle$ è un arco
    \begin{itemize}
        \item \textbf{in avanti} se $v$ è discendente di $u$
        \item \textbf{di attraversamento} altrimenti
    \end{itemize}
\end{itemize}
\subsection{Grafi non orientati}
Durante la DFS di un grafo orientato, ogni arco è percorso esattamente due volte. Definiamo:
\begin{itemize}
    \item \textbf{Arco dell'albero}: arco inserito nella foresta DFS
    \item \textbf{Arco all'indietro}: arco che collega un vertice ad un suo antenato
\end{itemize}
Durante la visita di un grafo orientato, un arco $\langle u,v \rangle$ viene percorso quando si incontra $v$ nella lista 
degli adiacenti ad $u$. In quel momento, color[$v$] può essere:
\begin{itemize}
    \item \textbf{bianco}: $(u,v)$ è un \textbf{arco dell'albero}
    \item \textbf{grigio}: $u$ è un discendente di $v$, $\langle u,v \rangle$ è un \textbf{arco all'indietro} 
    \item \textbf{nero}: $\langle u,v \rangle$ è un \textbf{arco all'indietro}
\end{itemize}
\subsection{Test di aciclicità}
\begin{theorem}[Grafo aciclico]
    Se un grafo (orientato o non orientato) contiene un ciclo, allora esiste un arco all'indietro. Viceversa, se una visita 
    in profondità produce un arco all'indietro, il grafo contiene un ciclo. Quindi, un grafo è aciclico se e solo se una 
    visita DFS non produce archi all'indietro.
\end{theorem} 
\begin{algorithm}[H]
    \caption{CICLICO(G)}
    \begin{algorithmic}
        \State INIZIALIZZA(G)
        \For{ogni nodo $u$ di $G$}
            \If{color[$u$] = white \textbf{and} VISITA RICORSIVA CICLO(G,u)}
                \State \textbf{return} true
            \EndIf 
        \EndFor
        \State \textbf{return} false
    \end{algorithmic}
\end{algorithm}
\begin{algorithm}[H]
    \caption{VISITA RICORSIVA CICLO(G,u)}
    \begin{algorithmic}
        \State color[$u$] $\gets$ gray
        \For{ogni $v$ adiacente ad $u$}
            \If{color[$v$ = white]}
                \State $\pi[v] \gets u$
                \If{VISITA RICORSIVA CICLO(G,v)}
                    \State \textbf{return} true
                \EndIf
                \ElsIf{$v\neq \pi[u]$ (color[$v$] = gray \textit{per grafi orientati})}
                    \State \textbf{return} true
            \EndIf 
        \EndFor 
        \State color[$u$] $\gets$ black 
        \State \textbf{return} false
    \end{algorithmic}
\end{algorithm}
\section{Ordinamento topologico}
Dato un \textbf{grafo orientato aciclico} (DAG) è sempre possibile ordinare i nodi in un \textbf{ordine topologico}, cioè 
in modo che non ci sia nessun arco all'indietro nell'ordinamento.
\subsection{Raggiungibilità}
In un DAG, la relazione di \textbf{raggiungibilità} è una relazione di ordine parziale:
\begin{itemize}
    \item è riflessiva: ogni vertice è raggiungibile da se stesso 
    \item è antisimmetrica: se $v$ è raggiungibile da $u$ ed $u$ è raggiugibile da $v$, allora $v$ e $u$ sono coincidenti
    \item è transitiva: se $v$ è raggiungibile da $u$ e $w$ è raggiungibile da $v$, allora $w$ è raggiungibile da $u$
\end{itemize}
\subsection{Ordine topologico}
Dato un DAG, un \textbf{ordine topologico} è un ordine lineare dei suoi nodi tale che, se nel grafo vi è un arco $(u,v)$, 
allora $u$ precede $v$ nell'ordine. Un grafo aciclico possiede sempre un ordine topologico; un DAG può possedere diversi 
ordini topologici.
\subsubsection{Algoritmo astratto}
Il metodo più semplice ma meno efficiente per trovare un'ordinamento topologico. Si definiscono: \textbf{nodo sorgente} 
come nodo che non ha archi entranti, e \textbf{nodo pozzo} come nodo che non ha archi uscenti. Questo algoritmo funziona
rimuovendo nodi sorgente dal grafo $G'$ (memorizzandoli in una lista, $ord$) e sviluppando un sottoproblema.
\begin{theorem}
    $ord$ è un'ordinamento topologico di $G$. Denotiamo con $ord_i$ e $G'$ (copia del grafo $G$) il contenuto di $ord$ e
    $G'$ all'iterazione i-esima: ad ogni istante del ciclo, non può esserci nessun cammino in $G$ che porta da un vertice 
    in $G'$ ad uno in $ord$ ("all'indietro").
\end{theorem}
\begin{proof}
    Caso base: con $i=0$, la condizione è banalmente verificata ($ord$ non contiene vertici).
    Passo induttivo: ad un istante $k$, non c'è alcun cammino in $G$ dai vertici $G'_k$ ai vertici in $ord_k$, quindi 
    ad un istante $k+1$, non c'è alcun cammino in $G$ dai vertici $G'_{k+1}$ ai vertici in $ord_{k+1}$.\\
    Al passo k-esimo, si sceglie un vertice sorgente $u$ in $G'_k$: non ci sono cammini in $G$ che raggiungono $u$ passando solo 
    per i vertici di $G'_k$. Per ipotesi induttiva, aggiungendo $u$ ad $ord_k$ all'istante $k$, all'istante $k+1$ non ci 
    sarà alcun cammino in $G$ dai vertici di $G'_{k+1}$ ai vertici in $ord_{k+1}$.
\end{proof}
La complessità dell'algoritmo semplice è $\mathcal{O}(m*n)$.
\subsubsection{Ordinamento topologico basato su DFS}
\begin{theorem}[Ordinamento topologico]
    In una qualunque visita DFS, $f[v]<f[u]$ per ogni arco $\langle u,v \rangle$.
\end{theorem}
\begin{proof}
    Supponiamo per assurdo che si abbia $f[u]<f[v]$; quindi, apro e chiudo $u$ e poi apro e chiudo $v$, oppure apro $u$ 
    e $v$ e poi chiudo $u$ e $v$. Il primo caso è impossibile, perchè $u$ non può diventare nero prima che $v$ diventi 
    grigio, ossia prima che tutti i suoi adiacenti siano stati scoperti. Il secondo caso è impossibile perchè $u$ sarebbe 
    discendente di $v$ e l'arco $\langle u,v \rangle$ sarebbe un arco all'indietro, ma il grafo è aciclico.
\end{proof}
Per ottenere l'ordinamento topologico, basta tenere traccia dei vertici chiusi con una lista, che conterrà i vertici chiusi, 
dal più al meno recente.
\begin{algorithm}[H]
    \caption{TOPOLOGICAL SORT(G)}
    \begin{algorithmic}
        \State INIZIALIZZA(G)
        \State $ord \gets$ vettore di lunghezza n 
        \State $t \gets$ n-1
        \For{ogni $u \in V$}
            \If{color[$u$] = white}
                \State TOPOLOGICAL DFS(G,u,ord,t)
            \EndIf
        \EndFor\\
        \Return $ord$
    \end{algorithmic}
\end{algorithm}
\begin{algorithm}[H]
    \caption{TOPOLOGICAL DFS(G,u,ord,t)}
    \begin{algorithmic}
        \State color[$u$] $\gets$ gray 
        \State d[$u$] $\gets$ time $\gets$ time+1
        \For{ogni $v$ adiacente ad $u$}
            \If{color[$v$] = white}
                \State $\pi gets u$
                \State TOPOLOGICAL DFS(G,v,ord,t)
            \EndIf 
        \EndFor 
        \State color[$u$] $\gets$ black 
        \State f[$u$] $\gets$ time $\gets$ time+1
        \State $ord[t] \gets u$
        \State t--
    \end{algorithmic}
\end{algorithm}
La complessità è $\mathcal{O}(m+n)$.
\section{Componenti connesse e fortemente connesse}
\subsection{Componenti connesse}
In un grafo non orientato, la relazione di raggiungibilità è una relazione di equivalenza:
\begin{itemize}
    \item è \textbf{riflessiva}: per definizione, ogni vertice è raggiungibile da se stesso con un cammino degenere di 
    lunghezza 0
    \item è \textbf{simmetrica}: se $v$ è raggiungibile da $u$ tramite un cammino $p$, allora $u$ è raggiungibile da $v$ 
    percorrendo all'indietro lo stesso cammino
    \item è \textbf{transitiva}: se $v$ è raggiungibile da $u$ e $w$ è raggiungibile da $v$, allora $w$ è raggiungibile 
    da $u$, percorrendo il cammino da $u$ a $v$ e da $v$ a $w$.
\end{itemize}
In un grafo non orientato, le componenti connesse sono le classi di equivalenza della relazione di raggiungibilità. Una 
visita di un grafo restituisce esattamente una componente connessa di quel grafo (l'albero di visita).
\begin{algorithm}[H]
    \caption{COMPONENTI CONNESSE(G)}
    \begin{algorithmic}
        \State INIZIALIZZA(G)
        \State $\Pi \gets$ foresta vuota 
        \For{ogni $u \in V$}
            \If{color[$u$] = white}
                \State $\pi_u \gets$ VISITA(G,u) ($\pi_u$ è l'albero di visita)
                \State $\Pi \gets \Pi+{\pi_u}$
            \EndIf 
        \EndFor\\
        \Return $\Pi$
    \end{algorithmic}
\end{algorithm}
Il grafo è connesso se e solo se nell'albero di visita tutti i vertici hanno un predecessore eccetto il nodo sorgente.
\begin{algorithm}
    \caption{CONNESSIONE(G)}
    \begin{algorithmic}
        \State INIZIALIZZA(G)
        \State scegli vertice $s$ appartenente a $G$
        \State $\pi \gets$ VISITA(G,s)
        \For{ogni $u$ appartenente a $G$}
            \If{$u\neq s$ e $\pi[u]$=NULL}
            \Return false 
            \EndIf
        \EndFor\\ 
        \Return true
    \end{algorithmic}
\end{algorithm}
La complessità è $\mathcal{O}(m+n)$.
\subsection{Componenti fortemente connesse}
In un grafo orientato $G$, due nodi, $u$ e $v$ si dicono mutualmente raggiungibili o \textbf{fortemente connessi} se 
ognuno dei due è raggiungibile dall'altro, cioè esiste un cammino da $u$ a $v$ e da $v$ a $u$ ($u \leftrightarrow v$).
La connessione forte è una relazione di equivalenza.
Una \textbf{cfc} di un grafo orientato $G$ è un sottografo $G'$ di $G$ fortemente connesso e massimale: i nodi di $G'$ sono 
tutti fra loro fortemente connessi e nessun altro nodo di $G$ è fortemente connesso con nodi di $G'$. Ogni vertice del grafo 
fa parte di una cfc, in quanto ogni nodo è almeno fortemente connesso con se stesso. Da un grafo fortemente connesso è possibile 
ricavare un DAG (e quindi un ordinamento topologico). 

Per trovare la cfc contenente un vertice $x$:
\begin{itemize}
    \item calcoliamo i \textbf{discendenti} di $x$ (D($x$)), ossia i vertici di $G$ raggiungibili da $x$
    \item calcoliamo gli \textbf{antenati} di $x$ (A($x$)), ossia i vertici che raggiungono $x$
    \item cfc[$x$] è data dall'\textbf{intersezione} tra l'insieme degli antenati e dei discendenti ($D(x)\cap A(x)$)
\end{itemize}
Questo algoritmo è molto costoso, $\mathcal{O}(n^2+m)$.
\begin{lemma}[Cammino fortemente connesso]
    Se due vertici $x,y$ di un grafo sono in una stessa cfc, allora nessun cammino tra di essi può abbandonare tale cfc.
\end{lemma}
\begin{proof}
    Sia $z$ tale che $x\rightarrow z$ e $z\rightarrow y$. $z$ è banalmente raggiungibile da $x$ per ipotesi ($x\rightarrow z$); 
    siccome $x,y$ appartengono alla stessa cfc, esisterà un cammino $y\rightarrow x$. Esiste anche $z\rightarrow y$ per 
    ipotesi. Quindi, per concatenazione, esisterà anche un cammino $z\rightarrow y\rightarrow x$.
\end{proof}
\begin{theorem}[Sottoalbero fortemente connesso]
    In una qualunque DFS di un grafo $G$ orientato, tutti i vertici di una cfc vengono collocati in uno stesso sottoalbero.
\end{theorem}
\begin{proof}
    Sia $r$ il primo vertice di una data cfc che viene scoperto dalla DFS: da $r$ sono raggiungibili tutti gli altri vertici 
    della cfc (per definizione). Poichè $r$ è il primo vertice ad essere stato scoperto, al momento della sua scoperta tutti 
    gli altri vertici della cfc saranno bianchi. Per il lemma precedente, tutti i cammini da $r$ agli altri vertici della 
    cfc conterranno solo vertici bianchi che fanno parte della cfc. Allora, per il \textbf{teorema del cammino bianco}, 
    tutti i vertici appartenenti alla cfc di $r$ saranno discendenti di $r$ nell'albero DFS.
\end{proof}
\begin{proprietà}[1]
    Esiste sempre, per ogni grafo diretto, almeno un ordine di visita DFS dei suoi nodi tale per cui le cfc sono già 
    separate nella foresta di visita.
\end{proprietà}
\begin{proprietà}[2]
    Un grafo $G$ ed il suo trasposto $G^T$ hanno le stesse cfc.
\end{proprietà}
Siano $x$ e $y$ due vertici di un grafo $G$; assumiamo che $x$ non sia sulla stessa cfc di $y$. Dopo la DFS su $G$ si possono 
presentare i seguenti casi:
\begin{enumerate}
    \item \textbf{$y$ è discendente di $x$} in un albero della foresta DFS di $G$. Esiste un cammino da $x$ a $y$, ma non
    il contrario, quindi non esisterà un cammino da $x$ a $y$ in $G^T$ ($d[x]<d[y]<f[y]<f[x]$).
    \item \textbf{$x$ e $y$ non sono uno discendente dell'altro} nella foresta DFS di $G$. Non può esistere nessun cammino 
    da $y$ a $x$, altrimenti $x$ sarebbe nel sottoalbero di $y$. Quindi, non eeisterà il cammino da $x$ a $y$ in $G^T$ 
    ($d[y]<f[y]<d[x]<f[x]$).
\end{enumerate}
In entrambi i casi, ($f[x]>f[y]$), quindi nella seconda visita i vertici saranno considerati in ordine decrescente di tempo 
di fine visita.

Da queste osservazioni, si ricava l'\textbf{algoritmo di Kosaraju}: 
\begin{enumerate}
    \item visita $G$ con l'algoritmo VISITA TUTTI I VERTICI DFS e costruisci una lista di vertici in ordine decrescente 
    dei tempi di fine visita 
    \item costruisci $G^T$
    \item visita $G^T$ con l'algoritmo VISITA TUTTI I VERTICI DFS, considerando i vertici nell'ordine trovato al passo 1 
\end{enumerate}
La complessità è pari a $\mathcal{O}(n+m)$.
Per dimostrare la correttezza dell'algoritmo, ci si avvale del \textbf{teorema del sottoalbero fortemente connesso} e dei 
lemmi seguenti.
\begin{lemma}[2]
    Un grafo orientato e il suo trasposto hanno le stesse cfc.
\end{lemma}
\begin{lemma}[3]
    Sia $A^T$ un albero ottenuto con la visita in profondità $G^T$, considerando i vertici in ordine decrescente dei tempi 
    di fine visita su $G$, e sia $u$ la sua radice. Per ogni vertice $v$ discendente di $u$ in $A^T$, $v$ e $u$ appartengono 
    alla stessa cfc.
\end{lemma}
\begin{proof}
    Dimostriamo che ogni discendente di $u$ in $A^T$ è anche un discendente di $u$ in un albero della foresta costruita 
    dalla DFS su $G$. La dimostrazione è fatta per assurdo.\\
    Consideriamo un cammino sull'albero $A^T$ a aprtire dalla radice $u$; sia $v$ il primo vertice sul cammino per cui il 
    lemma non vale (cioè $v$ non è discendente di $u$ nella visita di $G$) e sia $w$ il suo predecessore sul cammino. 
    L'enunciato è valido per $w$: $d[u]\leq d[w]<f[w]\leq f[u]$.\\
    Siccome la visita DFS di $G^T$ considera i vertici in ordine decrescente di fine visita, vale $f[v]<f[u]$.
    Per il \textbf{teorema delle parentesi}, se $v$ non è discendente di $u$ nella prima visita, deve valere $d[v]<f[v]<d[u]<f[u]$.
    Ma questo è impossibile, in quanto $v$ è adiacente a $w$ in $G$, e la visita di $v$ non può terminare prima che sia 
    iniziata la visita di un suo adiacente.\\
    Quindi in $G$ esiste un cammino da $u$ a $v$. Siccome $v$ è discendente di $u$ in $A^T$, esiste anche un cammino da 
    $u$ a $v$ in $G^T$, e quindi da $v$ a $u$ in $G$.
\end{proof}
L'algoritmo è quindi corretto.
\section{Tecnica greedy}
\subsection{Problemi}
Un \textbf{problema P} è definito come una relazione $P\subseteq I\times S$: $I$ è l'insieme delle possibili \textbf{istanze}
del problema e l'insieme $S$ è l'insieme delle possibili \textbf{soluzioni} del problema.
Tipi di problemi:
\begin{itemize}
    \item \textbf{problemi di decisione}: problemi che richiedono di verificare una certa proprietà sull'input (risultato 
    o vero o falso)
    \item \textbf{problemi di ricerca}: data un'istanza del problema, restituire una soluzione ammissibile
    \item \textbf{problemi di ottimizzazione}: data un'istanza di un problema ed una funzione obiettivo valuta(Sol), che per 
    ogni soluzione Sol restituisce un valore di tale soluzione Sol ottima
\end{itemize}
Una soluzione di un problema di ottimizzazione è anche una soluzione di un equivalente problema di ricerca (ma non viceversa).
\subsection{Problema dello zaino frazionario}
\subsubsection{Definizione}
Un ladro entra in un magazzino e trova $n$ oggetti. L'i-esimo oggetto $o_i$ ha un valore di $c_i$ euro e pesa $p_i$ chilogrammi.
$v_i=c_i/p_i$ è il valore per unità di peso. Gli oggetti sono frazionabili, quindi il ladro ne può prendere anche solo una 
frazione $x_1$, $0\leq x_i \leq 1$. In tal caso, il valore della parte presa sarà $c_ix_i$. Il ladro ha un solo zaino, che 
può contenere oggetti per un peso massimo di $P$ chilogrammi.

Quali oggetti e in quale quantità dovrà prendere il ladro per ottenere il massimo guadagno dal furto?
\subsubsection{Formalizzazione}
Il problema richiede di valorizzare $x_i$ per ogni $1\leq i \leq n$ in modo che $\sum x_ic_i$ sia massima. Due proprietà: 
\begin{itemize}
    \item \textbf{Ottimalità}. Tutte le soluzioni che massimizzano il valore totale dello zaino (la \textbf{funzione obiettivo}) 
    sono soluzioni ottime. 
    \item \textbf{Ammissibilità}.
\end{itemize}
\end{document}