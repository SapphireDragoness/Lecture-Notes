\documentclass[11pt]{article}
\usepackage[margin=.8in]{geometry}
\usepackage[italian]{babel}
\usepackage{graphicx}
\usepackage{amsmath}

\title{Teoria laboratorio FLT}

\begin{document}
\section{Introduzione}
\subsection{Sintassi e semantica}
La definizione di un linguaggio di programmazione deve includere la specificazione della sua \textit{sintassi} (struttura)
e \textit{semantiche} (significato). La sintassi definisce quali sequenze di caretteri sono ammesse.
\subsection{Organizzazione di un compilatore}
I compilatori generalmente svolgono i seguenti compiti:
\begin{itemize}
    \item \textit{analisi} del programma sorgente da compilare 
    \item \textit{sintesi} del programma destinazione 
\end{itemize}
\begin{center}
    \includegraphics{Screenshot 2024-01-12 111712.png}
\end{center}
Quasi tutti i compilatori moderni sono \textit{orientati alla sintassi}. I compilatori sintetizzano la struttura di un 
programma in un \textit{abstract syntax tree} (AST), che omette dettagli superflui. Il parser costruisc l'AST usando 
\textit{tokens}, i simboli elementari usati per definire la sintassi del linguaggio di programmazione. Il riconoscimento
della struttura sintattica è una parte importante della \textit{analisi sintattica}.

L'\textit{analisi semantica} esamina il significato (semantica) del programma, basandosi sulla sua struttura sintattica.

Nella \textit{fase di sintesi}, i costrutti del linguaggio sorgente sono tradotti in una \textit{rappresentazione
intermedia} (IR) del programma, anche se alcuni compilatori generano direttamente il codice di destinazione.
\subsubsection{Scanner}
Lo \textit{scanner} comincia l'analisi del programma sorgente leggendo carattere per carattere il testo in input, raggruppando 
i singoli caratteri in token (identificatori, interi, parole riservate, delimitatori). I token vengono solitamente codificati 
e passati al parser per l'analisi sintattica. Lo scanner svolge i seguenti compiti:
\begin{itemize}
    \item trasforma il programma in un flusso di token 
    \item elimina informazioni superflue (come i commenti)
    \item processa le direttive del compilatore
\end{itemize}
Le \textit{espressioni regolari} sono un metodo efficiente per descrivere i tokens.
\subsubsection{Parser}
Il parser è basato su specificazioni sintattiche formali come le grammatiche context-free. Legge i tokens e li raggruppa 
in frasi a seconda della specificazione della sintassi.

Il parser verifica che la sintassi sia corretta. Se incontra un errore di sintassi, riporta un messaggio di errore appropriato.
Inoltre, può tentare di rimediare all'errore.
\subsubsection{Type Checker}
Il \textit{type checker} controlla la \textit{semantica statica} di ogni nodo dell'AST: verifica che il costrutto che ogni 
nodo rappresenta sia legale e significativo. Se il costrutto è semanticmante corretto, il type checker decora il nodo 
dell'AST aggiungendo informazioni di tipo.

Il type checking dipende solamente dalle regole semantiche del linguaggio sorgente.
\subsubsection{Symbol tables}
Una \textit{symbol table} è un meccanismo che permette l'associazione di informazioni agli identificatori e la loro 
condivisione nelle fasi di compilazione.
\subsubsection{Generatore di codice}
Il codice intermedio prodotto da un traduttore è mappato sulla macchina di destinazione da un \textit{generatore di 
codice}.
\section{Un semplice compilatore}
\subsection{Definizione informale del linguaggio \textit{ac}}
Definiamo \textit{ac} informalmente:
\paragraph*{Tipi} In \textit{ac} esistono solo due tipi di dato: intero e float.
\paragraph*{Keywords} In \textit{ac} esistono tre tipi di parole riservate: float, int e print.
\paragraph*{Variabili} In \textit{ac} il nome della variabile è dichiarato dopo averne specificato il tipo.
La maggior parte dei linguaggi di programmazine possiede regole che dettano la conversione di tipo: in \textit{ac}, la 
conversione da intero a float avviene automaticamente.

Il linguaggio di destinazione è \textit{dc}, una calcolatrice a stack che utilizza la notazione polacca inversa.
\subsection{Definizione formale di \textit{ac}}
Useremo una grammatica context-free per specificare la sintassi del linguaggio e espressioni regolari per specificare i 
simboli del linguaggio.
\subsubsection{Specifica della sintassi}
Il linguaggio \textit{ac} è specificato da una grammatica context-free (CFG), un insieme di \textit{produzioni}.

La produzioni fanno riferimento a due tipi di simboli: i \textit{terminali} e \textit{non terminali}. Un terminale è un 
simbolo della grammatica che non può essere riscritto.

Una CFG descrive in maniera compatta e formale tutti i programmi che possono essere generati da un dato linguaggio di 
programmazione. Per generare un programma, si inizia da uno speciale simbolo non terminale, detto \textit{assioma}, che 
solitamente è il simbolo nella parte sinistra (LHS) della prima regola di produzione della grammatica. 

La generazione procede rimpiazzando non terminali con altri non terminali o terminali, secondo le regole della grammatica.
Il simbolo $\varepsilon$ rappresenta la \textit{stringa vuota}, che indica l'assenza di simboli nella parte sinistra di 
una produzione. Il simbolo \$ rappresenta la fine dell'input.

\subsubsection{Specifica dei tokens}
La specificazione formale dei token di un linguaggio viene tipicamente compiuta con associando \textit{espressioni 
regolari} ad ogni token.
\subsection{Fasi del compilatore}
\begin{enumerate}
    \item Lo scanner legge il programma sorgente da un file di testo e produce un flusso di tokens. Le parole riservate 
    vengono distinte da nomi di variabili.
    \item Il parser processa i tokens, ne determina la validità sintattica e crea un AST. 
    \item L'AST così creata viene attraversata per creare una symbol table. Questa tabella associa tipo e altre informazioni 
    alle variabili usate nel programma sorgente.
    \item L'AST viene attraversato per eseguire l'analisi semantica. L'analisi semantica decora o trasforma parti dell'AST 
    man mano che il significato di tali parti diventa chiaro.
    \item Infine, l'AST viene attraversato per generare la traduzione del programma sorgente.
\end{enumerate}
\subsection{Scanning}
Il compito dello scanner è quello di trasformare un flusso di caratteri in un flusso di token. dove ogni token rappresenta 
un'istanza di un simbolo terminale. Ogni token scandito dallo scanner possiede un \textit{tipo} e \textit{valore semantico}.
\subsection{Parsing}
Il parser controlla la validità del flusso di tokens. La \textit{discesa ricorsiva} è una delle più semplici tecniche di 
parsing: ogni non terminale è associato ad una procedura di parsing che determina se il token nel flusso contiene una 
sequenza di token derivabile da quel non terminale.
\subsection{Abstract Syntax Trees}
Lo scanner e il parser svolgono la fase di \textit{analisi sintattica} di un compilatore. L'AST contiene informazioni 
essenziali derivate dall'albero di parsing.
\subsection{Analisi semantica}
Durante l'analisi semantica vengono svolte le seguenti operazioni:
\begin{itemize}
    \item le dichiarazioni e gli scope sono processati per costruire una \textit{symbol table}
    \item i tipi definiti dal linguaggio e dall'utente sono esaminati per assicurarne la consistenza
\end{itemize}
\subsubsection{Symbol tables}
La costruzione della symbol table è un'attività di processamento semantico durante la quale l'AST viene attraversato per 
registrare tutti gli identificatori ed i loro tipi in una \textit{symbol table}.
\subsubsection{Type checking}
Il linguaggio \textit{ac} offre solo due tipi, intero e float, e tutti gli identificatori devono avere il loro tipo 
dichiarato. Una volta che la symbol table è stata costruita, il tipo di ogni identificatore è conosciuto, e si può verificare 
la consistenza dei tipi.

Durante il type checking, l'AST viene attraversato dal basso verso l'alto, ed ad ogni nodo viene applicato il metodo 
visitor appropriato:
\begin{itemize}
    \item Per le costanti e i simboli, il visitor imposta il tipo del modo basandosi su contenuti dello stesso.
    \item Per nodi che computano valori, viene eventualmente effettuata conversione di tipo.
    \item Per l'operazione di assegnamento, il visitor si assicura che il valore calcolato dal secondo nodo sia dello 
    stesso tipo del primo nodo.
\end{itemize}
\subsection{Generazione del codice}
L'ultimo compito del compilatore è la formulazione di codice che rappresenti le semantiche del programma sorgente. 
Per \textit{ac}, il linguaggio di destinazione è \textit{dc}, una calcolatrice basata su stack. 

La generazione del codice avviene attraversando l'AST, dalla radice alle foglie (top-down).
\section{Scanning}
\subsection{Espressioni regolari}
Le espressioni regolari sono un modo conveniente per specificare semplici insiemi di stringhe. Un insieme di stringhe 
definito da espressioni regolari è detto \textit{insieme regolare}.

Le stringhe vengono costruite dall'alfabeto $\Sigma$ tramite \textit{concatenazione}.
\subsection{Automi a stati finiti e scanners}
Un'\textit{automa a stati finiti} può essere usato per riconoscere i token specificati da un'espressione regolare. 
Un'automa a stati finiti consiste in:
\begin{itemize}
    \item un insieme finito di \textit{stati}
    \item un \textit{alfabeto}, $\Sigma$
    \item un insieme di \textit{transizioni} da uno stato ad un altro, etichettati con i caratteri in $\Sigma$
    \item uno \textit{stato iniziale}
    \item un sottoinsieme degli stati detti \textit{finali}
\end{itemize}
\section{Grammatiche e parsing}
\subsection{Grammatiche context-free}
Formalmente, un \textit{linguaggio} è un insieme di strighe di lunghezza finita su un alfabeto. Una \textit{grammatica 
context-free} è una rappresentazione compatta e finita di un linguaggio, definito dai seguenti:
\begin{itemize}
    \item un \textit{alfabeto dei terminali} $\Sigma$
    \item un \textit{alfabeto dei non terminali} $V$
    \item un'\textit{assioma} $S$
    \item un insieme finito di produzioni $P$
\end{itemize}
Iniziando dall'assioma, i non terminali sono riscritti usando le regole di produzione finchè non rimangono solo terminali.
Ogni riscrittura è un passo nella \textit{derivazione} della stringa risultante.
\subsubsection{Derivazione sinistra e destra}
Una derivazione che sceglie sempre il non terminale più a sinistra è detta \textit{derivazione sinistra}.
Una derivazione che sceglie sempre il non terminale più a destra è detta \textit{derivazione destra}.
\subsubsection{Albero di parsing}
Una derivazione può essere rappresentata da un \textit{albero di parsing}: l'assioma rappresenta la radice, i nodi interni
sono non terminali e le foglie sono terminali.
\subsection{Algoritmi per l'analisi delle grammatiche}
\subsubsection{Algoritmo First}
Un insieme comunemente usato dai generatori di parser è \texttt{First($\alpha$)}. Questo è l'insieme di tutti i simboli 
terminali che possono iniziare una frase derivabile dalla stringa di simboli grammaticali in $\alpha$. Formalmente,
\begin{equation*}
    \texttt{First($\alpha$)}=\{a\in\Sigma|\alpha\Rightarrow^*a\beta\}
\end{equation*}
\texttt{First($\alpha$)} è calcolato scandendo $\alpha$ da sinistra a destra. Se $\alpha$ inizia con il simbolo terminale
$a$, allora $\texttt{First($\alpha$)}=\{a\}$. Se si incontra un simbolo non terminale $A$, allora devono essere consultate
le produzioni di $A$.
\subsubsection{Algoritmo Follow}
Gli algoritmi per la costruzione di parser spesso richiedono di calcolare l'insieme di terminali che può seguire un non 
terminale $A$. Ogni non terminale eccetto l'assioma deve avere un insieme di follow non vuoto. Formalmente,
\begin{equation*}
    \texttt{Follow($A$)}=\{b\in\Sigma|S\Rightarrow^+\alpha Ab\beta\}
\end{equation*}
\texttt{Follow($A$)} fornisce il contesto destro associato al non terminale $A$. 
\section{Parsing Top-Down}
\subsection{Grammatiche LL(k)}
Passi per costruire un parser a discesa ricorsiva:
\begin{itemize}
    \item ad ogni non terminale $A$ viene associata una procedura di parsing
    \item la procedura associata ad $A$ viene incaricata allo svolgimento di un passo della derivazione scegliendo e applicando
    una delle produzioni di $A$
    \item il parser sceglie la produzione appropriata per $A$ ispezionando i $K$ token successivi in input (l'insieme 
    predict)
\end{itemize}
Generalmente, la scelta di produzione può essere determinata sui $k$ token successivi nell'input, per una costante $k$
scelta a priori. Questi $k$ tokens sono detti \textit{lookahead} di un parser LL(k). Se è possibile costruire un parser 
LL(k) per una CFG, allora la CFG è detta \textit{grammatica LL(k)}.

Un parser LL(K) può controllare i $k$ tokens successivi e decidere quale produzione applicare. La funzione \texttt{Predict($p$)}
considera la produzione $p$ e calcola l'insieme dei token che predicono l'applicazione della regola di produzione $p$.
Consideriamo di dover effettuare il parsing della stringa $\alpha a\beta\in\Sigma^*$. Supponiamo che il parser abbia 
costruito la derivazione $S\Rightarrow^*\alpha Ay_1\dots y_n$. A questo punto, $\alpha$ è stato abbinato e $A$ è il non 
terminale più a sinistra nella derivazione. Quindi, dev'essere applicata almeno una produzione per $A$ per poter continuare 
la derivazione sinistra. Poichè la stringa in input contiene una $a$ come prossimo token, il parsing deve continuare con 
una produzione per $A$ che derivi $a$ come primo simbolo terminale.

Esaminiamo l'insieme di produzioni:
\begin{equation*}
    P=\{p\in\texttt{ProduzioniPer($A$)}|a\in\texttt{Predict($p$)}\}
\end{equation*}
Si deve verificare una delle seguenti condizioni:
\begin{itemize}
    \item 
\end{itemize}
\end{document}